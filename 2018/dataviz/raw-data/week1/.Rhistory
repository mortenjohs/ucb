library(stringr)
library(scales)
library(DT)
# regexes for parsing tweets
replace_reg <- "https?://[^\\s]+|&amp;|&lt;|&gt;|\\bRT\\b"
unnest_reg <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"
url_reg <- "http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+"
tweets <- data_frame()
for (n in c(1:9)) {
tmp <- read_csv(paste0("https://raw.githubusercontent.com/fivethirtyeight/russian-troll-tweets/master/IRAhandle_tweets_",n,".csv"))
tweets <- bind_rows(tweets,tmp)
}
datatable(head(Fearmonger_bigram_freqs,1000),rownames = FALSE)
View(tweet_category_day)
nonenglish_jul21_2016 <- bigrams %>%
filter(account_category == "NonEnglish"
& tweet_date == "2016-06-21") %>%
count(bigram) %>%
arrange(-n)
library(knitr)
opts_chunk$set(out.width="900px", dpi=300)
# load required packages
library(readr)
library(dplyr)
library(ggplot2)
library(tidytext)
library(wordcloud)
library(lubridate)
library(tidyr)
library(stringr)
library(scales)
library(DT)
# regexes for parsing tweets
replace_reg <- "https?://[^\\s]+|&amp;|&lt;|&gt;|\\bRT\\b"
unnest_reg <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"
url_reg <- "http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+"
tweets <- data_frame()
for (n in c(1:9)) {
tmp <- read_csv(paste0("https://raw.githubusercontent.com/fivethirtyeight/russian-troll-tweets/master/IRAhandle_tweets_",n,".csv"))
tweets <- bind_rows(tweets,tmp)
}
datatable(head(nonenglish_jul21_2016,1000),rownames = FALSE)
library(knitr)
opts_chunk$set(out.width="900px", dpi=300)
# load required packages
library(readr)
library(dplyr)
library(ggplot2)
library(tidytext)
library(wordcloud)
library(lubridate)
library(tidyr)
library(stringr)
library(scales)
library(DT)
# regexes for parsing tweets
replace_reg <- "https?://[^\\s]+|&amp;|&lt;|&gt;|\\bRT\\b"
unnest_reg <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"
url_reg <- "http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+"
tweets <- data_frame()
for (n in c(1:9)) {
tmp <- read_csv(paste0("https://raw.githubusercontent.com/fivethirtyeight/russian-troll-tweets/master/IRAhandle_tweets_",n,".csv"))
tweets <- bind_rows(tweets,tmp)
}
# processing for dates/times
tweets <- tweets %>%
separate(publish_date, into = c("tweet_date", "tweet_time"), sep = " ", remove = TRUE) %>%
mutate(tweet_date = as.Date(tweet_date, format = "%m/%d/%Y")) %>%
separate(tweet_time, into = c("hour","minute"), sep = ":", remove = TRUE) %>%
mutate(hour = as.integer(hour),
minute = as.integer(minute),
tweet_time = hour + minute/60,
year = year(tweet_date),
month = month(tweet_date),
weekday = weekdays(tweet_date, abbreviate=TRUE)) %>%
filter(tweet_date >= "2015-06-19")
# tweets per day, by category
tweet_category_day <- tweets %>%
group_by(tweet_date,account_category) %>%
count()
ggplot(tweet_category_day, aes(x=tweet_date, y=n, color=account_category, fill=account_category)) +
scale_fill_brewer(palette = "Paired") +
scale_color_brewer(palette = "Paired") +
geom_area() +
xlab("") +
ylab("") +
scale_y_continuous(labels = comma) +
scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
theme_minimal(base_size = 16, base_family = "ProximaNova-Semibold") +
facet_wrap(~account_category, ncol = 4) +
theme(legend.position = "none",
panel.grid.minor.x = element_blank())
# tweets by time of day and account category
ggplot(tweets, aes(y=tweet_time, x=account_category, fill=account_category)) +
scale_y_continuous(limits = c(1,24),
breaks = c(6,12,18),
labels = c("6am","Noon","6pm")) +
scale_fill_brewer(palette = "Paired", guide=FALSE) +
geom_violin(size = 0, alpha = 0.7) +
xlab("") +
ylab("") +
geom_hline(yintercept=seq(3, 24, by = 3), color = "gray", size = 0.1) +
coord_flip() +
theme_minimal(base_size = 16, base_family = "ProximaNova-Semibold") +
theme(panel.grid = element_blank())
# tweets per weekday, by category
tweet_category_weekday <- tweets %>%
group_by(weekday,account_category) %>%
count()
ggplot(tweet_category_weekday, aes(x=weekday, y=n, fill=account_category)) +
geom_bar(stat = "identity") +
scale_fill_brewer(palette = "Paired", guide=FALSE) +
scale_x_discrete(limits = c("Sun","Mon","Tue","Wed","Thu","Fri","Sat"), labels=c("Su","M","Tu","W","Th","F","Sa")) +
scale_y_continuous(labels = comma) +
xlab("") +
ylab("") +
theme_minimal(base_size = 16, base_family = "ProximaNova-Semibold") +
facet_wrap(~account_category, ncol = 4) +
theme(panel.grid.major.x = element_blank(),
panel.grid.minor.x = element_blank())
# bigrams
bigrams <- tweets %>%
mutate(text = str_replace_all(content, replace_reg, "")) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
separate(bigram, into = c("first","second"), sep = " ", remove = FALSE) %>%
# remove tidytext stop words
anti_join(stop_words, by = c("first" = "word")) %>%
anti_join(stop_words, by = c("second" = "word")) %>%
filter(str_detect(first, "[a-z]"),
str_detect(second, "[a-z]"))
nonenglish_jul21_2016 <- bigrams %>%
filter(account_category == "NonEnglish"
& tweet_date == "2016-07-21") %>%
count(bigram) %>%
arrange(-n)
save.image("~/SpiderOak Hive/russian_trolls/trolls.RData")
library(dbplyr)
View(head(tweets))
tweets_edited <- tweets %>%
select(author,content,tweet_date,tweet_time,account_category)
# load required packages
library(dplyr)
tweets_edited <- tweets %>%
select(author,content,tweet_date,tweet_time,account_category)
View(head(tweets_edited))
con <- DBI::dbConnect(RSQLite::SQLite(), path = ":memory:")
library(dbplyr)
con <- DBI::dbConnect(RSQLite::SQLite(), path = ":memory:")
con <- DBI::dbConnect(RSQLite::SQLite(), path = ":memory:")
install.packages("RSQLite")
library(RSQLite)
install.packages("DBI")
library(dbplyr)
library(RSQLite)
tweets_edited <- tweets %>%
select(author,content,tweet_date,tweet_time,account_category)
install.packages("DBI")
# load required packages
library(dplyr)
library(dbplyr)
library(RSQLite)
con <- DBI::dbConnect(RSQLite::SQLite(), path = ":memory:")
tweets_edited <- tweets %>%
select(author,content,tweet_date,tweet_time,account_category)
View(head(tweets))
tweets_edited <- tweets %>%
select(author,content,tweet_date,tweet_time,following,followers,updates,account_category)
setwd("~/SpiderOak Hive/russian_trolls")
mydb <- dbConnect(RSQLite::SQLite(), "troll_tweets.db")
tweets_edited <- tweets %>%
select(author,content,tweet_date,tweet_time,following,followers,updates,account_category)
copy_to(mydb, tweets_edited, "tweets",
temporary = FALSE,
indexes = list(
"author",
"tweet_date",
"account_category"
)
)
View(tweet_category_day)
tweets_category_day <- tweets_category_day %>%
arrange(-n)
tweet_category_day <- tweet_category_day %>%
arrange(-n)
tweet_category_day <- tweet_category_day %>%
rename(tweets = n) %>%
arrange(-n)
View(tweet_category_day)
tweet_category_day <- tweet_category_day %>%
rename(tweets = n) %>%
arrange(-n)
tweet_category_day <- tweet_category_day %>%
rename(tweets = n) %>%
arrange(-tweets)
View(tweet_category_day)
View(tweet_category_day)
copy_to(mydb, tweets_category_day, "tweet_category_day",
temporary = FALSE,
indexes = list(
"account_category",
"tweet_date"
)
)
copy_to(mydb, tweet_category_day, "tweets_category_day",
temporary = FALSE,
indexes = list(
"account_category",
"tweet_date"
)
)
View(tweets_edited)
glimpse(tweets_edited)
tweets_edited <- tweets %>%
select(author,content,tweet_date,tweet_time,following,followers,updates,account_category) %>%
mutate(tweet_date = as.character(tweet_date))
glimpse(tweets_edited)
mydb <- dbConnect(RSQLite::SQLite(), "troll_tweets.db")
copy_to(mydb, tweets_edited, "tweets",
temporary = FALSE,
indexes = list(
"author",
"tweet_date",
"account_category"
)
)
View(tweet_category_day)
View(tweet_category_day)
copy_to(mydb, tweet_category_day, "tweets_category_day",
temporary = FALSE,
indexes = list(
"account_category",
"tweet_date"
)
)
tweet_category_day <- tweet_category_day %>%
rename(tweets = n) %>%
arrange(-tweets) %>%
mutate(tweet_date = as.character(tweet_date))
tweet_category_day <- tweet_category_day %>%
# rename(tweets = n) %>%
arrange(-tweets) %>%
mutate(tweet_date = as.character(tweet_date))
# edit tweets by daya data and write to db
tweet_category_day <- tweet_category_day %>%
# rename(tweets = n) %>%
arrange(-tweets) %>%
ungroup() %>%
mutate(tweet_date = as.character(tweet_date))
# create db
mydb <- dbConnect(RSQLite::SQLite(), "troll_tweets.db")
copy_to(mydb, tweets_edited, "tweets",
temporary = FALSE,
indexes = list(
"author",
"tweet_date",
"account_category"
)
)
# edit tweets by daya data and write to db
tweet_category_day <- tweet_category_day %>%
# rename(tweets = n) %>%
arrange(-tweets) %>%
ungroup() %>%
mutate(tweet_date = as.character(tweet_date))
copy_to(mydb, tweet_category_day, "tweets_category_day",
temporary = FALSE,
indexes = list(
"account_category",
"tweet_date"
)
)
library(knitr)
opts_chunk$set(out.width="900px", dpi=300)
sort(unique(tweets$account_category)
sort(unique(tweets$account_category)
sort(unique(tweets$account_category)))
sort(unique(tweets$account_category))
View(head(tweets))
library(dplyr)
library(dbplyr)
library(RSQLite)
# create db
mydb <- dbConnect(RSQLite::SQLite(), "troll-tweets.db")
tweets_edited <- tweets %>%
select(author,content,tweet_date,tweet_time,following,followers,updates,account_category,language) %>%
mutate(tweet_date = as.character(tweet_date))
glimpse(tweets_edited)
copy_to(mydb, tweets_edited, "tweets",
temporary = FALSE,
indexes = list(
"author",
"tweet_date",
"account_category"
)
)
copy_to(mydb, tweets_edited, "tweets",
temporary = FALSE,
overwrite = TRUE,
indexes = list(
"author",
"tweet_date",
"account_category"
)
)
library(knitr)
opts_chunk$set(out.width="900px", dpi=300)
library(readr)
library(dplyr)
library(ggplot2)
library(tidytext)
library(wordcloud)
library(lubridate)
library(tidyr)
library(stringr)
library(scales)
library(DT)
library(longurl)
# regexes for parsing tweets
replace_reg <- "https?://[^\\s]+|&amp;|&lt;|&gt;|\\bRT\\b"
unnest_reg <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"
url_reg <- "http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+"
tweets <- data_frame()
tweets <- data_frame()
for (n in c(1:9)) {
tmp <- read_csv(paste0("https://raw.githubusercontent.com/fivethirtyeight/russian-troll-tweets/master/IRAhandle_tweets_",n,".csv"), col_types = cols(
.default = col_character(),
following = col_integer(),
followers = col_integer()
))
tweets <- bind_rows(tweets,tmp)
}
tweets <- data_frame()
for (n in c(1:9)) {
tmp <- read_csv(paste0("https://raw.githubusercontent.com/fivethirtyeight/russian-troll-tweets/master/IRAhandle_tweets_",n,".csv"), col_types = cols(
.default = col_character(),
following = col_integer(),
followers = col_integer()
))
tweets <- bind_rows(tweets,tmp)
}
tweets <- data_frame()
for (n in c(1:9)) {
tmp <- read_csv(paste0("https://raw.githubusercontent.com/fivethirtyeight/russian-troll-tweets/master/IRAhandle_tweets_",n,".csv"), col_types = cols(
.default = col_character(),
following = col_integer(),
followers = col_integer()
))
tweets <- bind_rows(tweets,tmp)
}
tmp <- read_csv("https://raw.githubusercontent.com/fivethirtyeight/russian-troll-tweets/master/IRAhandle_tweets_9.csv")
View(tmp)
tmp <- read_csv("https://raw.githubusercontent.com/fivethirtyeight/russian-troll-tweets/master/IRAhandle_tweets_9.csv")
tmp <- read_csv("https://raw.githubusercontent.com/fivethirtyeight/russian-troll-tweets/master/IRAhandle_tweets_9.csv")
library(ggplot2)
library(dplyr)
library(WDI)
library(readr)
library(scales)
library(rgdal)
Salaries <- filter(Salaries, yearID == 2016)
# load the Lahman package
library(Lahman)
Salaries <- filter(Salaries, yearID == 2016)
Salaries <- filter(Salaries, yearID == 2017)
Salaries <- filter(Salaries, yearID == 2016)
Salaries <- filter(Salaries, yearID == 2016)
# note - use the file from kdmc, which has some manual edits
Teams <- filter(Teams, yearID == 2015)
# join to Master and Teams, select fields for export
mlb_salaries_2016 <- inner_join(Salaries, Master, by="playerID") %>%
left_join(Teams, by=c("teamID"="teamIDBR")) %>%
mutate(salary_mil=salary/1000000, nameFull=paste(nameFirst, nameLast, sep=" ")) %>%
rename(teamName=name) %>%
select(playerID, nameFirst, nameLast, nameFull, teamID, teamName, salary, salary_mil)
missing <- anti_join(Salaries,mlb_salaries_2016, by="playerID")
ggplot(mlb_salaries_2016, aes(x=salary_mil, y=..count..)) +
geom_histogram(binwidth=0.5, fill = "red") +
ylab("Number of players") +
xlab("Salary ($ millions)") +
scale_x_continuous(limits = c(0,35)) +
theme_minimal(base_size = 14, base_family = "Georgia")
setwd("~/Dropbox/kdmc-workshops/2018/intro-dataviz/data")
mlb_salaries_2016 <- read_csv("mlb_salaries_2016.csv")
ggplot(mlb_salaries_2016, aes(x=salary_mil, y=..count..)) +
geom_histogram(binwidth=0.5, fill = "red") +
ylab("Number of players") +
xlab("Salary ($ millions)") +
scale_x_continuous(limits = c(0,35)) +
theme_minimal(base_size = 14, base_family = "Georgia")
setwd("~/Dropbox/ucb/2018/dataviz/raw-data/week1")
life_wealth_2016 <- WDI(indicator=c("NY.GDP.PCAP.PP.CD","SP.DYN.LE00.IN"), country="all", start=2016, end=2016, extra=TRUE) %>%
filter(income != "Aggregates") %>%
select(2,4,5,3) %>%
rename(gdp_pc=NY.GDP.PCAP.PP.CD,
life_expect=SP.DYN.LE00.IN)
View(life_wealth_2016)
ggplot(life_wealth_2016, aes(x=gdp_pc, y=life_expect)) +
geom_point(size=3, alpha=0.5) +
scale_x_continuous(labels = dollar) +
stat_smooth(formula=y~log(x), se=FALSE) +
xlab("GDP per capita") +
ylab("Life expectancy at birth") +
theme_minimal(base_size = 14, base_family = "Georgia")
ggplot(life_wealth_2016, aes(x=gdp_pc, y=life_expect)) +
geom_point(size=3, alpha=0.5) +
scale_x_log10(labels = dollar) +
geom_smooth(se=FALSE, method="lm") +
xlab("GDP per capita") +
ylab("Life expectancy at birth") +
theme_minimal(base_size = 14, base_family = "Georgia")
# life expectancy histogram
ggplot(life_wealth_2016, aes(x=life_expect, y=..count..)) +
geom_histogram(binwidth=0.5, fill = "red") +
ylab("Number of countries") +
xlab("Life expectancy at birth") +
# scale_x_continuous(labels = dollar, limits = c(-2500,160000)) +
theme_minimal(base_size = 14, base_family = "Georgia")
write.csv(life_wealth_2016, "life_wealth_2016.csv", row.names = FALSE, na = "")
ggplot(gdp_pc, aes(x=gdp_percap, y=..count..)) +
geom_histogram(binwidth=2500, fill = "red") +
ylab("Number of countries") +
xlab("GDP per capita (2015)") +
scale_x_continuous(labels = dollar, limits = c(-2500,160000)) +
theme_minimal(base_size = 14, base_family = "Georgia")
gdp_pc <- WDI(indicator="NY.GDP.PCAP.PP.CD", country="all", start=2016, end=2016, extra=TRUE) %>%
filter(income != "Aggregates") %>%
select(2,5,3) %>%
rename(gdp_percap=NY.GDP.PCAP.PP.CD)
ggplot(life_wealth, aes(x=gdp_percap, y=..count..)) +
geom_histogram(binwidth=2500, fill = "red") +
ylab("Number of countries") +
xlab("GDP per capita (2016)") +
scale_x_continuous(labels = dollar, limits = c(-2500,160000)) +
theme_minimal(base_size = 14, base_family = "Georgia")
ggplot(life_wealth_2016, aes(x=life_expect, y=..count..)) +
geom_histogram(binwidth=0.5, fill = "red") +
ylab("Number of countries") +
xlab("Life expectancy at birth (2016") +
# scale_x_continuous(labels = dollar, limits = c(-2500,160000)) +
theme_minimal(base_size = 14, base_family = "Georgia")
ggplot(life_wealth_2016, aes(x=life_expect, y=..count..)) +
geom_histogram(binwidth=0.5, fill = "red") +
ylab("Number of countries") +
xlab("Life expectancy at birth (2016)") +
# scale_x_continuous(labels = dollar, limits = c(-2500,160000)) +
theme_minimal(base_size = 14, base_family = "Georgia")
ggplot(life_wealth_2016, aes(x=gdp_percap, y=..count..)) +
geom_histogram(binwidth=2500, fill = "red") +
ylab("Number of countries") +
xlab("GDP per capita (2016)") +
scale_x_continuous(labels = dollar, limits = c(-2500,160000)) +
theme_minimal(base_size = 14, base_family = "Georgia")
View(life_wealth_2016)
life_wealth_2016 <- WDI(indicator=c("NY.GDP.PCAP.PP.CD","SP.DYN.LE00.IN"), country="all", start=2016, end=2016, extra=TRUE) %>%
filter(income != "Aggregates") %>%
select(2,4,5,3) %>%
rename(gdp_percap=NY.GDP.PCAP.PP.CD,
life_expect=SP.DYN.LE00.IN)
write.csv(life_wealth_2016, "life_wealth_2016.csv", row.names = FALSE, na = "")
ggplot(life_wealth_2016, aes(x=gdp_percap, y=..count..)) +
geom_histogram(binwidth=2500, fill = "red") +
ylab("Number of countries") +
xlab("GDP per capita (2016)") +
scale_x_continuous(labels = dollar, limits = c(-2500,160000)) +
theme_minimal(base_size = 14, base_family = "Georgia")
View(gdp_pc)
ggplot(life_wealth_2016, aes(x=gdp_percap, y=..count..)) +
geom_histogram(binwidth=2500, fill = "red") +
ylab("Number of countries") +
xlab("GDP per capita (2016)") +
scale_x_continuous(labels = dollar, limits = c(-2500,160000)) +
theme_minimal(base_size = 14, base_family = "Georgia")
ggplot(life_wealth_2016, aes(x=life_expect, y=..count..)) +
geom_histogram(binwidth=2, fill = "red") +
ylab("Number of countries") +
xlab("Life expectancy at birth (2016)") +
# scale_x_continuous(labels = dollar, limits = c(-2500,160000)) +
theme_minimal(base_size = 14, base_family = "Georgia")
ggplot(life_wealth_2016, aes(x=life_expect, y=..count..)) +
geom_histogram(binwidth=1, fill = "red") +
ylab("Number of countries") +
xlab("Life expectancy at birth (2016)") +
# scale_x_continuous(labels = dollar, limits = c(-2500,160000)) +
theme_minimal(base_size = 14, base_family = "Georgia")
ggplot(life_wealth_2016, aes(x=life_expect, y=..count..)) +
geom_histogram(binwidth=1.5, fill = "red") +
ylab("Number of countries") +
xlab("Life expectancy at birth (2016)") +
# scale_x_continuous(labels = dollar, limits = c(-2500,160000)) +
theme_minimal(base_size = 14, base_family = "Georgia")
ggplot(life_wealth_2016, aes(x=life_expect, y=..count..)) +
geom_histogram(binwidth=3, fill = "red") +
ylab("Number of countries") +
xlab("Life expectancy at birth (2016)") +
# scale_x_continuous(labels = dollar, limits = c(-2500,160000)) +
theme_minimal(base_size = 14, base_family = "Georgia")
ggplot(life_wealth_2016, aes(x=life_expect, y=..count..)) +
geom_histogram(binwidth=2.5, fill = "red") +
ylab("Number of countries") +
xlab("Life expectancy at birth (2016)") +
# scale_x_continuous(labels = dollar, limits = c(-2500,160000)) +
theme_minimal(base_size = 14, base_family = "Georgia")
ggplot(life_wealth_2016, aes(x=life_expect, y=..count..)) +
geom_histogram(binwidth=2, fill = "red") +
ylab("Number of countries") +
xlab("Life expectancy at birth (2016)") +
# scale_x_continuous(labels = dollar, limits = c(-2500,160000)) +
theme_minimal(base_size = 14, base_family = "Georgia")
View(mlb_salaries_2016)
2.3^6/500
2.3*10^6/500
4600*500
